{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T13:20:50.533755Z",
     "start_time": "2020-02-16T13:20:50.525520Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import collections\n",
    "# import utils as d2l\n",
    "import seq\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax屏蔽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T13:20:50.649164Z",
     "start_time": "2020-02-16T13:20:50.631361Z"
    }
   },
   "outputs": [],
   "source": [
    "# X:(batch_size,seq_len), X_len:(batch_size)\n",
    "def SequenceMask(X, X_len,value=-1e6):\n",
    "    maxlen = X.size(1)\n",
    "    #print(X.size(),torch.arange((maxlen),dtype=torch.float)[None, :],'\\n',X_len[:, None] )\n",
    "    mask = torch.arange((maxlen),dtype=torch.float)[None, :] >= X_len[:, None]   # 大于句子长度的位置填充1\n",
    "    #print(mask)\n",
    "    X[mask]=value  # 大于句子长度的位置赋值为-1e6，softmax后即为0\n",
    "    return X\n",
    "\n",
    "# X:(batch_size,seq_len),\n",
    "def masked_softmax(X, valid_length):\n",
    "    # X: 3-D tensor, valid_length: 1-D or 2-D tensor\n",
    "    softmax = nn.Softmax(dim=-1)\n",
    "    if valid_length is None:\n",
    "        return softmax(X)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_length.dim() == 1:\n",
    "            try:\n",
    "                valid_length = torch.FloatTensor(valid_length.numpy().repeat(shape[1], axis=0))#[2,2,3,3]\n",
    "            except:\n",
    "                valid_length = torch.FloatTensor(valid_length.cpu().numpy().repeat(shape[1], axis=0))#[2,2,3,3]\n",
    "        else:\n",
    "            valid_length = valid_length.reshape((-1,))\n",
    "        # fill masked elements with a large negative, whose exp is 0\n",
    "        X = SequenceMask(X.reshape((-1, shape[-1])), valid_length)\n",
    "\n",
    "        return softmax(X).reshape(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引入注意力机制的Seq2seq模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T13:20:50.798940Z",
     "start_time": "2020-02-16T13:20:50.688401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0000,  3.0000,  4.0000,  5.0000]],\n",
       "\n",
       "        [[10.0000, 11.0000, 12.0000, 13.0000]]], grad_fn=<BmmBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLPAttention(nn.Module):  \n",
    "    def __init__(self, units,ipt_dim,dropout, **kwargs):\n",
    "        super(MLPAttention, self).__init__(**kwargs)\n",
    "        # Use flatten=True to keep query's and key's 3-D shapes.\n",
    "        self.W_k = nn.Linear(ipt_dim, units, bias=False)\n",
    "        self.W_q = nn.Linear(ipt_dim, units, bias=False)\n",
    "        self.v = nn.Linear(units, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, key, value, valid_length):\n",
    "        query, key = self.W_k(query), self.W_q(key)  # (2,1,8), (2,10,8)\n",
    "#         print(\"query.size(),key.size():\",query.size(),key.size())  # size torch.Size([2, 1, 8]) torch.Size([2, 10, 8])\n",
    "        # expand query to (batch_size, #querys, 1, units),   (b,dq,1,h)\n",
    "        # and key to (batch_size, 1, #kv_pairs, units).   (b,1,dk,h)   Then plus them with broadcast.\n",
    "        features = query.unsqueeze(2) + key.unsqueeze(1)\n",
    "#         print(\"features:\",features.size())  # (2, 1, 10, 8)  # features: torch.Size([2, 1, 10, 8])\n",
    "        scores = self.v(features).squeeze(-1) \n",
    "        attention_weights = self.dropout(masked_softmax(scores, valid_length))\n",
    "        return torch.bmm(attention_weights, value)\n",
    "    \n",
    "atten = MLPAttention(ipt_dim=2,units = 8, dropout=0)\n",
    "keys = torch.ones((2,10,2),dtype=torch.float)\n",
    "values = torch.arange((40), dtype=torch.float).view(1,10,4).repeat(2,1,1)\n",
    "atten(torch.ones((2,1,2), dtype = torch.float), keys, values, torch.FloatTensor([2, 6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T13:20:50.921121Z",
     "start_time": "2020-02-16T13:20:50.803638Z"
    },
    "code_folding": [
     9,
     22
    ]
   },
   "outputs": [],
   "source": [
    "class Seq2SeqAttentionDecoder(seq.Decoder):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(Seq2SeqAttentionDecoder, self).__init__(**kwargs)\n",
    "        self.attention_cell = MLPAttention(num_hiddens,num_hiddens, dropout)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.LSTM(embed_size+ num_hiddens,num_hiddens, num_layers, dropout=dropout)\n",
    "        self.dense = nn.Linear(num_hiddens,vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_len, *args):\n",
    "        outputs, hidden_state = enc_outputs\n",
    "#         print(\"first:\",outputs.size(),hidden_state[0].size(),hidden_state[1].size())\n",
    "        # Transpose outputs to (batch_size, seq_len, hidden_size)\n",
    "        return (outputs.permute(1,0,-1), hidden_state, enc_valid_len)\n",
    "        #outputs.swapaxes(0, 1)\n",
    "        \n",
    "    def forward(self, X, state):\n",
    "        enc_outputs, hidden_state, enc_valid_len = state\n",
    "        #(\"X.size\",X.size())\n",
    "        X = self.embedding(X).transpose(0,1)\n",
    "#         print(\"Xembeding.size2\",X.size())\n",
    "        outputs = []\n",
    "        for l, x in enumerate(X):\n",
    "#             print(f\"\\n{l}-th token\")\n",
    "#             print(\"x.first.size()\",x.size())\n",
    "            # query shape: (batch_size, 1, hidden_size)\n",
    "            # select hidden state of the last rnn layer as query\n",
    "            query = hidden_state[0][-1].unsqueeze(1) # np.expand_dims(hidden_state[0][-1], axis=1)\n",
    "            # context has same shape as query\n",
    "#             print(\"query enc_outputs, enc_outputs:\\n\",query.size(), enc_outputs.size(), enc_outputs.size())\n",
    "            context = self.attention_cell(query, enc_outputs, enc_outputs, enc_valid_len)\n",
    "            # Concatenate on the feature dimension\n",
    "#             print(\"context.size:\",context.size())\n",
    "            x = torch.cat((context, x.unsqueeze(1)), dim=-1)\n",
    "            # Reshape x to (1, batch_size, embed_size+hidden_size)\n",
    "#             print(\"rnn\",x.size(), len(hidden_state))\n",
    "            out, hidden_state = self.rnn(x.transpose(0,1), hidden_state)\n",
    "            outputs.append(out)\n",
    "        outputs = self.dense(torch.cat(outputs, dim=0))\n",
    "        return outputs.transpose(0, 1), [enc_outputs, hidden_state,\n",
    "                                        enc_valid_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T13:20:51.067363Z",
     "start_time": "2020-02-16T13:20:50.926225Z"
    },
    "code_folding": [
     7,
     43,
     46,
     55,
     61
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from torch.utils import data\n",
    "import sys\n",
    "import collections\n",
    "\n",
    "class Vocab(object): # This class is saved in d2l.\n",
    "    def __init__(self, tokens, min_freq=0, use_special_tokens=False):\n",
    "        # sort by frequency and token\n",
    "        counter = collections.Counter(tokens)\n",
    "        token_freqs = sorted(counter.items(), key=lambda x: x[0])\n",
    "        token_freqs.sort(key=lambda x: x[1], reverse=True)\n",
    "        if use_special_tokens:\n",
    "            # padding, begin of sentence, end of sentence, unknown\n",
    "            self.pad, self.bos, self.eos, self.unk = (0, 1, 2, 3)\n",
    "            tokens = ['', '', '', '']\n",
    "        else:\n",
    "            self.unk = 0\n",
    "            tokens = ['']\n",
    "        tokens += [token for token, freq in token_freqs if freq >= min_freq]\n",
    "        self.idx_to_token = []\n",
    "        self.token_to_idx = dict()\n",
    "        for token in tokens:\n",
    "            self.idx_to_token.append(token)\n",
    "            self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        else:\n",
    "            return [self.__getitem__(token) for token in tokens]\n",
    "    \n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        else:\n",
    "            return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "        \n",
    "def load_data_nmt(batch_size, max_len, num_examples=1000):\n",
    "    \"\"\"Download an NMT dataset, return its vocabulary and data iterator.\"\"\"\n",
    "    # Download and preprocess\n",
    "    def preprocess_raw(text):\n",
    "        text = text.replace('\\u202f', ' ').replace('\\xa0', ' ')\n",
    "        out = ''\n",
    "        for i, char in enumerate(text.lower()):\n",
    "            if char in (',', '!', '.') and text[i-1] != ' ':\n",
    "                out += ' '\n",
    "            out += char\n",
    "        return out \n",
    "    \n",
    "    with open('/home/cc/holdshy/XJQ/Pytorch/Dive_into_DL/eng-fra.txt', 'r') as f:\n",
    "        raw_text = f.read()\n",
    "    text = preprocess_raw(raw_text)\n",
    "    \n",
    "    # Tokenize\n",
    "    source, target = [], []\n",
    "    for i, line in enumerate(text.split('\\n')):\n",
    "        if i >= num_examples:\n",
    "            break\n",
    "        parts = line.split('\\t')\n",
    "        if len(parts) >= 2:\n",
    "            source.append(parts[0].split(' '))\n",
    "            target.append(parts[1].split(' '))\n",
    "\n",
    "    # Build vocab\n",
    "    def build_vocab(tokens):\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "        return Vocab(tokens, min_freq=3, use_special_tokens=True)\n",
    "    src_vocab, tgt_vocab = build_vocab(source), build_vocab(target)\n",
    "\n",
    "    # Convert to index arrays\n",
    "    def pad(line, max_len, padding_token):\n",
    "        if len(line) > max_len:\n",
    "            return line[:max_len]\n",
    "        return line + [padding_token] * (max_len - len(line))\n",
    "\n",
    "    def build_array(lines, vocab, max_len, is_source):\n",
    "        lines = [vocab[line] for line in lines]\n",
    "        if not is_source:\n",
    "            lines = [[vocab.bos] + line + [vocab.eos] for line in lines]\n",
    "        array = torch.tensor([pad(line, max_len, vocab.pad) for line in lines])\n",
    "        valid_len = (array != vocab.pad).sum(1)\n",
    "        return array, valid_len\n",
    "\n",
    "    src_vocab, tgt_vocab = build_vocab(source), build_vocab(target)\n",
    "    src_array, src_valid_len = build_array(source, src_vocab, max_len, True)\n",
    "    tgt_array, tgt_valid_len = build_array(target, tgt_vocab, max_len, False)\n",
    "    train_data = data.TensorDataset(src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
    "    train_iter = data.DataLoader(train_data, batch_size, shuffle=True)\n",
    "    \n",
    "    return src_vocab, tgt_vocab, train_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T13:23:43.955262Z",
     "start_time": "2020-02-16T13:23:43.948249Z"
    }
   },
   "outputs": [],
   "source": [
    "def try_gpu():\n",
    "    \"\"\"If GPU is available, return torch.device as cuda:0; else return torch.device as cpu.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "#     device = torch.device('cpu')\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T13:23:46.975932Z",
     "start_time": "2020-02-16T13:23:44.970525Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.0\n",
    "batch_size, num_steps = 64, 10\n",
    "lr, num_epochs, ctx = 0.005, 500, try_gpu()\n",
    "\n",
    "src_vocab, tgt_vocab, train_iter = load_data_nmt(batch_size, num_steps)\n",
    "# print(train_iter)\n",
    "encoder = seq.Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "decoder = Seq2SeqAttentionDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "model = seq.EncoderDecoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T13:23:47.014491Z",
     "start_time": "2020-02-16T13:23:47.009302Z"
    }
   },
   "outputs": [],
   "source": [
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    # pred shape: (batch_size, seq_len, vocab_size)\n",
    "    # label shape: (batch_size, seq_len)\n",
    "    # valid_length shape: (batch_size, )\n",
    "    def forward(self, pred, label, valid_length):\n",
    "        # the sample weights shape should be (batch_size, seq_len)\n",
    "        weights = torch.ones_like(label)\n",
    "        weights = SequenceMask(weights, valid_length).float()\n",
    "        self.reduction='none'\n",
    "        output=super(MaskedSoftmaxCELoss, self).forward(pred.transpose(1,2), label)\n",
    "        return (output*weights).mean(dim=1)\n",
    "    \n",
    "def grad_clipping_nn(model, theta, device):\n",
    "    \"\"\"Clip the gradient for a nn model.\"\"\"\n",
    "    grad_clipping(model.parameters(), theta, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T13:23:50.875564Z",
     "start_time": "2020-02-16T13:23:50.856307Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_s2s_ch9(model, data_iter, lr, num_epochs, device):  # Saved in d2l\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    tic = time.time()\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        l_sum, num_tokens_sum = 0.0, 0.0\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_vlen, Y, Y_vlen = [x.to(device) for x in batch]\n",
    "            Y_input, Y_label, Y_vlen = Y[:,:-1], Y[:,1:], Y_vlen-1\n",
    "            \n",
    "            Y_hat, _ = model(X, Y_input, X_vlen, Y_vlen)\n",
    "            l = loss(Y_hat, Y_label, Y_vlen).sum()\n",
    "            l.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                seq.grad_clipping_nn(model, 5, device)\n",
    "                \n",
    "            num_tokens = Y_vlen.sum().item()\n",
    "            optimizer.step()\n",
    "            l_sum += l.sum().item()\n",
    "            num_tokens_sum += num_tokens\n",
    "        if epoch % 50 == 0:\n",
    "            print(\"epoch {0:4d},loss {1:.3f}, time {2:.1f} sec\".format( \n",
    "                  epoch, (l_sum/num_tokens_sum), time.time()-tic))\n",
    "            tic = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T13:36:24.245830Z",
     "start_time": "2020-02-16T13:24:39.787936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   50,loss 0.092, time 70.1 sec\n",
      "epoch  100,loss 0.041, time 69.6 sec\n",
      "epoch  150,loss 0.028, time 70.7 sec\n",
      "epoch  200,loss 0.027, time 70.5 sec\n",
      "epoch  250,loss 0.023, time 70.0 sec\n",
      "epoch  300,loss 0.028, time 70.2 sec\n",
      "epoch  350,loss 0.021, time 70.4 sec\n",
      "epoch  400,loss 0.021, time 71.4 sec\n",
      "epoch  450,loss 0.021, time 70.9 sec\n",
      "epoch  500,loss 0.021, time 70.7 sec\n"
     ]
    }
   ],
   "source": [
    "seq.train_s2s_ch9(model, train_iter, lr, num_epochs, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T13:40:15.714899Z",
     "start_time": "2020-02-16T13:40:15.665528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go . => va !\n",
      "Good Night ! =>   !\n",
      "I'm OK . => je vais bien .\n",
      "I won ! => je l'ai emporté !\n"
     ]
    }
   ],
   "source": [
    "for sentence in ['Go .', 'Good Night !', \"I'm OK .\", 'I won !']:\n",
    "    print(sentence + ' => ' + seq.predict_s2s_ch9(\n",
    "        model, sentence, src_vocab, tgt_vocab, num_steps, ctx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go . => va !\n",
    "# Good Night ! =>   !\n",
    "# I'm OK . => ça va .\n",
    "# I won ! => j'ai gagné !"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "592.5px",
    "left": "153px",
    "top": "213.964px",
    "width": "179.141px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
