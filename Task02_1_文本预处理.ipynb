{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_635azvh",
    "id": "B4BA5B0FCB884B6DBA6FFE071318505E",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 文本预处理\n",
    "\n",
    "\n",
    "文本是一类序列数据，一篇文章可以看作是字符或单词的序列，本节将介绍文本数据的常见预处理步骤，预处理通常包括四个步骤：\n",
    "\n",
    "1. 读入文本\n",
    "2. 分词\n",
    "3. 建立字典，将每个词映射到一个唯一的索引（index）\n",
    "4. 将文本从词的序列转换为索引的序列，方便输入模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_da72pg7",
    "id": "C3B3705CB33847A895AD10619F23E97B",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 读入文本\n",
    "\n",
    "我们用一部英文小说，即H. G. Well的[Time Machine](http://www.gutenberg.org/ebooks/35)，作为示例，展示文本预处理的具体过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T14:08:12.432045Z",
     "start_time": "2020-02-13T14:08:12.392165Z"
    },
    "graffitiCellId": "id_ytfpat1",
    "id": "7FA4C53DED4F42279EA3AB3229B88DB7",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sentences 3221\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" \n",
    "\n",
    "import collections\n",
    "import re\n",
    "\n",
    "# re.sub(pattern, repl, string, count=0, flags=0)\n",
    "# pattern：表示正则表达式中的模式字符串； '[^a-z]+'\n",
    "# repl：被替换的字符串（既可以是字符串，也可以是函数）； ' '\n",
    "# string：要被处理的，要被替换的字符串； line.strip().lower()\n",
    "# count：匹配的次数, 默认是全部替换\n",
    "\n",
    "def read_time_machine():\n",
    "    with open('/home/cc/holdshy/XJQ/Pytorch/Dive_into_DL/timemachine.txt', 'r') as f:\n",
    "        lines = [re.sub('[^a-z]+', ' ', line.strip().lower()) for line in f]\n",
    "    return lines\n",
    "\n",
    "lines = read_time_machine()\n",
    "print('# sentences %d' % len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T14:08:12.571864Z",
     "start_time": "2020-02-13T14:08:12.488686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is hello delicious food\n",
      " 124 46 67 \n"
     ]
    }
   ],
   "source": [
    "content = 'is124hello46delicious67food'\n",
    "print(re.sub('[^a-z]+', ' ', content.strip().lower()))\n",
    "print(re.sub('[^0-9]+', ' ', content.strip().lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_gy3tram",
    "id": "EABE813C62FC4E1B8DFFD7B819C31829",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 分词\n",
    "\n",
    "我们对每个句子进行分词，也就是将一个句子划分成若干个词（token），转换为一个词的序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T14:08:12.709513Z",
     "start_time": "2020-02-13T14:08:12.576195Z"
    },
    "graffitiCellId": "id_z5grfxp",
    "id": "F80F8AFC1C0A48BDB66D52A18DC3A940",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 'time', 'machine', 'by', 'h', 'g', 'wells', ''], ['']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(sentences, token='word'):\n",
    "    \"\"\"Split sentences into word or char tokens\"\"\"\n",
    "    if token == 'word':\n",
    "        return [sentence.split(' ') for sentence in sentences]\n",
    "    elif token == 'char':\n",
    "        return [list(sentence) for sentence in sentences]\n",
    "    else:\n",
    "        print('ERROR: unkown token type '+token)\n",
    "\n",
    "# for line in lines:\n",
    "#     # ['t', 'h', 'e', ' ', 't', 'i', 'm', 'e', ' ', 'm', 'a', 'c', 'h', 'i', 'n', 'e', ' ', 'b', 'y', ' ', 'h', ' ', 'g', ' ', 'w', 'e', 'l', 'l', 's', ' ']'''\n",
    "# #     print(list(line))\n",
    "#     # the time machine by h g wells \n",
    "#     print(line)\n",
    "    \n",
    "tokens = tokenize(lines)  # 3221行，每行为单词的列表\n",
    "tokens[0:2]\n",
    "# tokens = tokenize(lines, token='char')\n",
    "# tokens[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_rap2ka4",
    "id": "01CE759264D84FAA8C60CE9156B86157",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 建立字典\n",
    "\n",
    "为了方便模型处理，我们需要将字符串转换为数字。因此我们需要先构建一个字典（vocabulary），将每个词映射到一个唯一的索引编号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T14:08:12.781978Z",
     "start_time": "2020-02-13T14:08:12.712423Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "9"
    },
    "graffitiCellId": "id_wapwqkb",
    "id": "37532FBF89C242A1805534BBE05C343A",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [['the', 'time', 'machine', 'by', 'h', 'g', 'wells', ''],\n",
    "#  [''],\n",
    "#  [''],\n",
    "# tokens\n",
    "class Vocab(object):\n",
    "    def __init__(self, tokens, min_freq=0, use_special_tokens=False):\n",
    "        counter = count_corpus(tokens)  # : \n",
    "        self.token_freqs = list(counter.items())\n",
    "        self.idx_to_token = []\n",
    "        if use_special_tokens:\n",
    "            # padding, begin of sentence, end of sentence, unknown\n",
    "            self.pad, self.bos, self.eos, self.unk = (0, 1, 2, 3)\n",
    "            self.idx_to_token += ['', '', '', '']\n",
    "        else:\n",
    "            self.unk = 0\n",
    "            # idx_to_token=['', 'the', 'time', 'machine', 'by', 'h', 'g', 'wells', 'i', 'traveller', ......]\n",
    "            self.idx_to_token += ['']\n",
    "        \n",
    "        self.idx_to_token += [token for token, freq in self.token_freqs\n",
    "                        if freq >= min_freq and token not in self.idx_to_token]\n",
    "        # token_to_idx=[('', 0), ('the', 1), ('time', 2), ('machine', 3), ('by', 4), ('h', 5), ('g', 6), ('wells', 7), ('i', 8), ('traveller', 9)]\n",
    "        self.token_to_idx = dict()\n",
    "        for idx, token in enumerate(self.idx_to_token):\n",
    "            self.token_to_idx[token] = idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):  # 已知词(字典;列表,元组)tokens，取出索引idx\n",
    "        # token_to_idx=[('', 0), ('the', 1), ('time', 2), ('machine', 3), ('by', 4), ('h', 5), ('g', 6), ('wells', 7), ('i', 8), \n",
    "        if not isinstance(tokens, (list, tuple)):  # 字典\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):  # 已知索引idx，取出词tokens\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        # idx_to_token=['', 'the', 'time', 'machine', 'by', 'h', 'g', 'wells', 'i', 'traveller', ......]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "def count_corpus(sentences):\n",
    "    tokens = [tk for st in sentences for tk in st]\n",
    "    return collections.Counter(tokens)  # 返回一个字典，记录每个词的出现次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T10:14:25.563693Z",
     "start_time": "2020-02-12T10:14:25.504674Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'the': 2261,\n",
       "         'time': 200,\n",
       "         'machine': 85,\n",
       "         'by': 103,\n",
       "         'h': 1,\n",
       "         'g': 1,\n",
       "         'wells': 9,\n",
       "         '': 1282,\n",
       "         'i': 1267,\n",
       "         'traveller': 61,\n",
       "         'for': 221,\n",
       "         'so': 112,\n",
       "         'it': 437,\n",
       "         'will': 37,\n",
       "         'be': 93,\n",
       "         'convenient': 5,\n",
       "         'to': 695,\n",
       "         'speak': 6,\n",
       "         'of': 1155,\n",
       "         'him': 40,\n",
       "         'was': 552,\n",
       "         'expounding': 2,\n",
       "         'a': 816,\n",
       "         'recondite': 1,\n",
       "         'matter': 6,\n",
       "         'us': 35,\n",
       "         'his': 129,\n",
       "         'grey': 11,\n",
       "         'eyes': 35,\n",
       "         'shone': 8,\n",
       "         'and': 1245,\n",
       "         'twinkled': 1,\n",
       "         'usually': 3,\n",
       "         'pale': 10,\n",
       "         'face': 38,\n",
       "         'flushed': 2,\n",
       "         'animated': 3,\n",
       "         'fire': 30,\n",
       "         'burned': 6,\n",
       "         'brightly': 4,\n",
       "         'soft': 16,\n",
       "         'radiance': 1,\n",
       "         'incandescent': 1,\n",
       "         'lights': 1,\n",
       "         'in': 541,\n",
       "         'lilies': 1,\n",
       "         'silver': 6,\n",
       "         'caught': 10,\n",
       "         'bubbles': 1,\n",
       "         'that': 443,\n",
       "         'flashed': 4,\n",
       "         'passed': 13,\n",
       "         'our': 57,\n",
       "         'glasses': 1,\n",
       "         'chairs': 2,\n",
       "         'being': 14,\n",
       "         'patents': 1,\n",
       "         'embraced': 1,\n",
       "         'caressed': 2,\n",
       "         'rather': 18,\n",
       "         'than': 34,\n",
       "         'submitted': 1,\n",
       "         'sat': 22,\n",
       "         'upon': 113,\n",
       "         'there': 127,\n",
       "         'luxurious': 1,\n",
       "         'after': 37,\n",
       "         'dinner': 13,\n",
       "         'atmosphere': 2,\n",
       "         'when': 55,\n",
       "         'thought': 57,\n",
       "         'roams': 1,\n",
       "         'gracefully': 1,\n",
       "         'free': 4,\n",
       "         'trammels': 1,\n",
       "         'precision': 1,\n",
       "         'he': 123,\n",
       "         'put': 34,\n",
       "         'this': 152,\n",
       "         'way': 38,\n",
       "         'marking': 2,\n",
       "         'points': 3,\n",
       "         'with': 216,\n",
       "         'lean': 2,\n",
       "         'forefinger': 2,\n",
       "         'as': 270,\n",
       "         'we': 82,\n",
       "         'lazily': 1,\n",
       "         'admired': 1,\n",
       "         'earnestness': 1,\n",
       "         'over': 54,\n",
       "         'new': 28,\n",
       "         'paradox': 5,\n",
       "         'fecundity': 1,\n",
       "         'you': 137,\n",
       "         'must': 49,\n",
       "         'follow': 8,\n",
       "         'me': 281,\n",
       "         'carefully': 6,\n",
       "         'shall': 7,\n",
       "         'have': 122,\n",
       "         'controvert': 1,\n",
       "         'one': 120,\n",
       "         'or': 84,\n",
       "         'two': 28,\n",
       "         'ideas': 3,\n",
       "         'are': 48,\n",
       "         'almost': 23,\n",
       "         'universally': 1,\n",
       "         'accepted': 5,\n",
       "         'geometry': 4,\n",
       "         'instance': 10,\n",
       "         'they': 122,\n",
       "         'taught': 2,\n",
       "         'at': 243,\n",
       "         'school': 1,\n",
       "         'is': 106,\n",
       "         'founded': 1,\n",
       "         'on': 137,\n",
       "         'misconception': 1,\n",
       "         'not': 114,\n",
       "         'large': 14,\n",
       "         'thing': 66,\n",
       "         'expect': 4,\n",
       "         'begin': 4,\n",
       "         'said': 89,\n",
       "         'filby': 17,\n",
       "         'an': 84,\n",
       "         'argumentative': 1,\n",
       "         'person': 2,\n",
       "         'red': 26,\n",
       "         'hair': 6,\n",
       "         'do': 22,\n",
       "         'mean': 7,\n",
       "         'ask': 2,\n",
       "         'accept': 1,\n",
       "         'anything': 5,\n",
       "         'without': 14,\n",
       "         'reasonable': 2,\n",
       "         'ground': 17,\n",
       "         'soon': 21,\n",
       "         'admit': 4,\n",
       "         'much': 23,\n",
       "         'need': 7,\n",
       "         'from': 122,\n",
       "         'know': 29,\n",
       "         'course': 12,\n",
       "         'mathematical': 3,\n",
       "         'line': 11,\n",
       "         'thickness': 5,\n",
       "         'nil': 1,\n",
       "         'has': 22,\n",
       "         'no': 92,\n",
       "         'real': 9,\n",
       "         'existence': 6,\n",
       "         'neither': 2,\n",
       "         'plane': 1,\n",
       "         'these': 74,\n",
       "         'things': 34,\n",
       "         'mere': 16,\n",
       "         'abstractions': 1,\n",
       "         'all': 118,\n",
       "         'right': 14,\n",
       "         'psychologist': 25,\n",
       "         'nor': 9,\n",
       "         'having': 4,\n",
       "         'only': 46,\n",
       "         'length': 8,\n",
       "         'breadth': 3,\n",
       "         'can': 22,\n",
       "         'cube': 3,\n",
       "         'object': 5,\n",
       "         'solid': 3,\n",
       "         'body': 6,\n",
       "         'may': 33,\n",
       "         'exist': 2,\n",
       "         'most': 27,\n",
       "         'people': 46,\n",
       "         'think': 36,\n",
       "         'but': 204,\n",
       "         'wait': 6,\n",
       "         'moment': 31,\n",
       "         'instantaneous': 1,\n",
       "         'don': 16,\n",
       "         't': 27,\n",
       "         'does': 4,\n",
       "         'last': 47,\n",
       "         'any': 40,\n",
       "         'became': 8,\n",
       "         'pensive': 1,\n",
       "         'clearly': 12,\n",
       "         'proceeded': 4,\n",
       "         'extension': 1,\n",
       "         'four': 15,\n",
       "         'directions': 2,\n",
       "         'duration': 1,\n",
       "         'through': 49,\n",
       "         'natural': 7,\n",
       "         'infirmity': 1,\n",
       "         'flesh': 3,\n",
       "         'which': 85,\n",
       "         'explain': 9,\n",
       "         'incline': 2,\n",
       "         'overlook': 2,\n",
       "         'fact': 8,\n",
       "         'really': 11,\n",
       "         'dimensions': 15,\n",
       "         'three': 24,\n",
       "         'call': 4,\n",
       "         'planes': 2,\n",
       "         'space': 25,\n",
       "         'fourth': 6,\n",
       "         'however': 16,\n",
       "         'tendency': 5,\n",
       "         'draw': 1,\n",
       "         'unreal': 3,\n",
       "         'distinction': 1,\n",
       "         'between': 16,\n",
       "         'former': 2,\n",
       "         'latter': 4,\n",
       "         'because': 11,\n",
       "         'happens': 1,\n",
       "         'consciousness': 2,\n",
       "         'moves': 2,\n",
       "         'intermittently': 1,\n",
       "         'direction': 6,\n",
       "         'along': 21,\n",
       "         'beginning': 5,\n",
       "         'end': 25,\n",
       "         'lives': 2,\n",
       "         'very': 85,\n",
       "         'young': 8,\n",
       "         'man': 70,\n",
       "         'making': 6,\n",
       "         'spasmodic': 2,\n",
       "         'efforts': 3,\n",
       "         'relight': 1,\n",
       "         'cigar': 4,\n",
       "         'lamp': 13,\n",
       "         'clear': 13,\n",
       "         'indeed': 20,\n",
       "         'now': 79,\n",
       "         'remarkable': 3,\n",
       "         'extensively': 1,\n",
       "         'overlooked': 2,\n",
       "         'continued': 3,\n",
       "         'slight': 5,\n",
       "         'accession': 1,\n",
       "         'cheerfulness': 1,\n",
       "         'what': 77,\n",
       "         'meant': 3,\n",
       "         'dimension': 8,\n",
       "         'though': 19,\n",
       "         'some': 94,\n",
       "         'who': 26,\n",
       "         'talk': 2,\n",
       "         'about': 70,\n",
       "         'another': 37,\n",
       "         'looking': 24,\n",
       "         'difference': 5,\n",
       "         'except': 7,\n",
       "         'foolish': 5,\n",
       "         'got': 25,\n",
       "         'hold': 5,\n",
       "         'wrong': 10,\n",
       "         'side': 21,\n",
       "         'idea': 10,\n",
       "         'heard': 20,\n",
       "         'say': 20,\n",
       "         'provincial': 4,\n",
       "         'mayor': 4,\n",
       "         'simply': 11,\n",
       "         'mathematicians': 1,\n",
       "         'spoken': 2,\n",
       "         'always': 10,\n",
       "         'definable': 1,\n",
       "         'reference': 2,\n",
       "         'each': 15,\n",
       "         'angles': 2,\n",
       "         'others': 12,\n",
       "         'philosophical': 2,\n",
       "         'been': 75,\n",
       "         'asking': 1,\n",
       "         'why': 16,\n",
       "         'particularly': 4,\n",
       "         'other': 36,\n",
       "         'even': 50,\n",
       "         'tried': 22,\n",
       "         'construct': 1,\n",
       "         'professor': 1,\n",
       "         'simon': 1,\n",
       "         'newcomb': 1,\n",
       "         'york': 1,\n",
       "         'society': 3,\n",
       "         'month': 2,\n",
       "         'ago': 9,\n",
       "         'how': 43,\n",
       "         'flat': 2,\n",
       "         'surface': 8,\n",
       "         'represent': 2,\n",
       "         'figure': 11,\n",
       "         'dimensional': 2,\n",
       "         'similarly': 1,\n",
       "         'models': 1,\n",
       "         'could': 92,\n",
       "         'if': 49,\n",
       "         'master': 1,\n",
       "         'perspective': 1,\n",
       "         'see': 45,\n",
       "         'murmured': 1,\n",
       "         'knitting': 1,\n",
       "         'brows': 1,\n",
       "         'lapsed': 1,\n",
       "         'into': 114,\n",
       "         'introspective': 1,\n",
       "         'state': 5,\n",
       "         'lips': 5,\n",
       "         'moving': 9,\n",
       "         'repeats': 1,\n",
       "         'mystic': 1,\n",
       "         'words': 6,\n",
       "         'yes': 3,\n",
       "         'brightening': 1,\n",
       "         'quite': 10,\n",
       "         'transitory': 2,\n",
       "         'manner': 4,\n",
       "         'well': 37,\n",
       "         'mind': 35,\n",
       "         'telling': 8,\n",
       "         'work': 10,\n",
       "         'my': 440,\n",
       "         'results': 2,\n",
       "         'curious': 4,\n",
       "         'here': 43,\n",
       "         'portrait': 1,\n",
       "         'eight': 11,\n",
       "         'years': 17,\n",
       "         'old': 28,\n",
       "         'fifteen': 2,\n",
       "         'seventeen': 2,\n",
       "         'twenty': 3,\n",
       "         'evidently': 6,\n",
       "         'sections': 1,\n",
       "         'were': 158,\n",
       "         'representations': 1,\n",
       "         'dimensioned': 1,\n",
       "         'fixed': 1,\n",
       "         'unalterable': 1,\n",
       "         'scientific': 3,\n",
       "         'pause': 5,\n",
       "         'required': 1,\n",
       "         'proper': 4,\n",
       "         'assimilation': 1,\n",
       "         'kind': 20,\n",
       "         'popular': 1,\n",
       "         'diagram': 1,\n",
       "         'weather': 4,\n",
       "         'record': 1,\n",
       "         'trace': 7,\n",
       "         'finger': 3,\n",
       "         'shows': 1,\n",
       "         'movement': 4,\n",
       "         'barometer': 1,\n",
       "         'yesterday': 2,\n",
       "         'high': 7,\n",
       "         'night': 39,\n",
       "         'fell': 16,\n",
       "         'then': 134,\n",
       "         'morning': 16,\n",
       "         'rose': 13,\n",
       "         'again': 62,\n",
       "         'gently': 5,\n",
       "         'upward': 2,\n",
       "         'surely': 1,\n",
       "         'mercury': 2,\n",
       "         'did': 41,\n",
       "         'generally': 2,\n",
       "         'recognized': 5,\n",
       "         'certainly': 7,\n",
       "         'traced': 1,\n",
       "         'such': 32,\n",
       "         'therefore': 2,\n",
       "         'conclude': 1,\n",
       "         'medical': 24,\n",
       "         'staring': 3,\n",
       "         'hard': 7,\n",
       "         'coal': 1,\n",
       "         'regarded': 2,\n",
       "         'something': 16,\n",
       "         'different': 7,\n",
       "         'cannot': 18,\n",
       "         'move': 13,\n",
       "         'smiled': 5,\n",
       "         'sure': 7,\n",
       "         'freely': 3,\n",
       "         'left': 26,\n",
       "         'go': 19,\n",
       "         'backward': 3,\n",
       "         'forward': 8,\n",
       "         'enough': 28,\n",
       "         'men': 14,\n",
       "         'done': 11,\n",
       "         'up': 71,\n",
       "         'down': 87,\n",
       "         'gravitation': 2,\n",
       "         'limits': 1,\n",
       "         'exactly': 10,\n",
       "         'balloons': 2,\n",
       "         'before': 48,\n",
       "         'save': 11,\n",
       "         'jumping': 1,\n",
       "         'inequalities': 1,\n",
       "         'had': 354,\n",
       "         'freedom': 4,\n",
       "         'vertical': 2,\n",
       "         'still': 53,\n",
       "         'little': 113,\n",
       "         'easier': 2,\n",
       "         'far': 22,\n",
       "         'get': 21,\n",
       "         'away': 36,\n",
       "         'present': 7,\n",
       "         'dear': 1,\n",
       "         'sir': 2,\n",
       "         'just': 17,\n",
       "         'where': 31,\n",
       "         'whole': 15,\n",
       "         'world': 52,\n",
       "         'gone': 20,\n",
       "         'getting': 6,\n",
       "         'mental': 3,\n",
       "         'existences': 1,\n",
       "         'immaterial': 1,\n",
       "         'passing': 4,\n",
       "         'uniform': 2,\n",
       "         'velocity': 5,\n",
       "         'cradle': 1,\n",
       "         'grave': 2,\n",
       "         'should': 23,\n",
       "         'travel': 9,\n",
       "         'began': 40,\n",
       "         'fifty': 2,\n",
       "         'miles': 4,\n",
       "         'above': 23,\n",
       "         'earth': 21,\n",
       "         's': 70,\n",
       "         'great': 42,\n",
       "         'difficulty': 4,\n",
       "         'interrupted': 1,\n",
       "         'germ': 1,\n",
       "         'discovery': 3,\n",
       "         'am': 12,\n",
       "         'recalling': 1,\n",
       "         'incident': 1,\n",
       "         'vividly': 3,\n",
       "         'back': 40,\n",
       "         'instant': 2,\n",
       "         'its': 69,\n",
       "         'occurrence': 1,\n",
       "         'become': 7,\n",
       "         'absent': 1,\n",
       "         'minded': 3,\n",
       "         'jump': 2,\n",
       "         'means': 6,\n",
       "         'staying': 2,\n",
       "         'more': 59,\n",
       "         'savage': 4,\n",
       "         'animal': 10,\n",
       "         'six': 1,\n",
       "         'feet': 18,\n",
       "         'civilized': 2,\n",
       "         'better': 10,\n",
       "         'off': 29,\n",
       "         'respect': 1,\n",
       "         'against': 32,\n",
       "         'balloon': 1,\n",
       "         'hope': 6,\n",
       "         'ultimately': 2,\n",
       "         'able': 3,\n",
       "         'stop': 7,\n",
       "         'accelerate': 1,\n",
       "         'drift': 3,\n",
       "         'turn': 3,\n",
       "         'oh': 1,\n",
       "         'reason': 6,\n",
       "         'show': 4,\n",
       "         'black': 30,\n",
       "         'white': 59,\n",
       "         'argument': 1,\n",
       "         'never': 20,\n",
       "         'convince': 1,\n",
       "         'possibly': 11,\n",
       "         'investigations': 1,\n",
       "         'long': 34,\n",
       "         'vague': 6,\n",
       "         'inkling': 1,\n",
       "         'exclaimed': 1,\n",
       "         'indifferently': 1,\n",
       "         'driver': 1,\n",
       "         'determines': 1,\n",
       "         'contented': 2,\n",
       "         'himself': 5,\n",
       "         'laughter': 4,\n",
       "         'experimental': 2,\n",
       "         'verification': 3,\n",
       "         'would': 60,\n",
       "         'remarkably': 1,\n",
       "         'historian': 1,\n",
       "         'suggested': 6,\n",
       "         'might': 35,\n",
       "         'verify': 2,\n",
       "         'account': 7,\n",
       "         'battle': 3,\n",
       "         'hastings': 1,\n",
       "         'attract': 1,\n",
       "         'attention': 7,\n",
       "         'ancestors': 2,\n",
       "         'tolerance': 1,\n",
       "         'anachronisms': 1,\n",
       "         'greek': 2,\n",
       "         'homer': 1,\n",
       "         'plato': 1,\n",
       "         'case': 7,\n",
       "         'plough': 1,\n",
       "         'german': 1,\n",
       "         'scholars': 1,\n",
       "         'improved': 1,\n",
       "         'future': 21,\n",
       "         'invest': 1,\n",
       "         'money': 1,\n",
       "         'leave': 7,\n",
       "         'accumulate': 1,\n",
       "         'interest': 9,\n",
       "         'hurry': 1,\n",
       "         'ahead': 2,\n",
       "         'discover': 3,\n",
       "         'erected': 1,\n",
       "         'strictly': 1,\n",
       "         'communistic': 1,\n",
       "         'basis': 1,\n",
       "         'wild': 5,\n",
       "         'extravagant': 1,\n",
       "         'theories': 3,\n",
       "         'seemed': 72,\n",
       "         'talked': 2,\n",
       "         'until': 20,\n",
       "         'cried': 6,\n",
       "         'going': 16,\n",
       "         'experiment': 3,\n",
       "         'brain': 2,\n",
       "         'weary': 4,\n",
       "         'let': 10,\n",
       "         'your': 8,\n",
       "         'anyhow': 1,\n",
       "         'humbug': 1,\n",
       "         'round': 36,\n",
       "         'smiling': 4,\n",
       "         'faintly': 2,\n",
       "         'hands': 28,\n",
       "         'deep': 5,\n",
       "         'trousers': 1,\n",
       "         'pockets': 3,\n",
       "         'walked': 10,\n",
       "         'slowly': 7,\n",
       "         'out': 73,\n",
       "         'room': 19,\n",
       "         'slippers': 1,\n",
       "         'shuffling': 1,\n",
       "         'passage': 4,\n",
       "         'laboratory': 19,\n",
       "         'looked': 34,\n",
       "         'wonder': 5,\n",
       "         'sleight': 1,\n",
       "         'hand': 49,\n",
       "         'trick': 6,\n",
       "         'tell': 13,\n",
       "         'conjurer': 1,\n",
       "         'seen': 22,\n",
       "         'burslem': 1,\n",
       "         'finished': 2,\n",
       "         'preface': 1,\n",
       "         'came': 105,\n",
       "         'anecdote': 1,\n",
       "         'collapsed': 2,\n",
       "         'held': 7,\n",
       "         'glittering': 2,\n",
       "         'metallic': 5,\n",
       "         'framework': 2,\n",
       "         'scarcely': 4,\n",
       "         'larger': 10,\n",
       "         'small': 13,\n",
       "         'clock': 5,\n",
       "         'delicately': 1,\n",
       "         'made': 36,\n",
       "         'ivory': 6,\n",
       "         'transparent': 2,\n",
       "         'crystalline': 2,\n",
       "         'substance': 4,\n",
       "         'explicit': 2,\n",
       "         'follows': 1,\n",
       "         'unless': 3,\n",
       "         'explanation': 5,\n",
       "         'absolutely': 11,\n",
       "         'unaccountable': 1,\n",
       "         'took': 32,\n",
       "         'octagonal': 1,\n",
       "         'tables': 5,\n",
       "         'scattered': 3,\n",
       "         'set': 13,\n",
       "         'front': 6,\n",
       "         'legs': 4,\n",
       "         'hearthrug': 1,\n",
       "         'table': 17,\n",
       "         'placed': 3,\n",
       "         'mechanism': 7,\n",
       "         'drew': 6,\n",
       "         'chair': 6,\n",
       "         'shaded': 1,\n",
       "         'bright': 15,\n",
       "         'light': 43,\n",
       "         'model': 8,\n",
       "         'also': 5,\n",
       "         'perhaps': 35,\n",
       "         'dozen': 3,\n",
       "         'candles': 3,\n",
       "         'brass': 5,\n",
       "         'candlesticks': 1,\n",
       "         'mantel': 3,\n",
       "         'several': 11,\n",
       "         'sconces': 1,\n",
       "         'brilliantly': 2,\n",
       "         'illuminated': 3,\n",
       "         'low': 5,\n",
       "         'arm': 9,\n",
       "         'nearest': 2,\n",
       "         'fireplace': 1,\n",
       "         'behind': 16,\n",
       "         'shoulder': 9,\n",
       "         'watched': 5,\n",
       "         'profile': 1,\n",
       "         'stood': 24,\n",
       "         'alert': 1,\n",
       "         'appears': 1,\n",
       "         'incredible': 6,\n",
       "         'subtly': 1,\n",
       "         'conceived': 1,\n",
       "         'adroitly': 1,\n",
       "         'played': 2,\n",
       "         'under': 42,\n",
       "         'conditions': 11,\n",
       "         'affair': 1,\n",
       "         'resting': 2,\n",
       "         'elbows': 1,\n",
       "         'pressing': 1,\n",
       "         'together': 8,\n",
       "         'apparatus': 3,\n",
       "         'plan': 2,\n",
       "         'notice': 2,\n",
       "         'looks': 1,\n",
       "         'singularly': 4,\n",
       "         'askew': 2,\n",
       "         'odd': 14,\n",
       "         'twinkling': 3,\n",
       "         'appearance': 3,\n",
       "         'bar': 9,\n",
       "         'pointed': 6,\n",
       "         'part': 21,\n",
       "         'lever': 17,\n",
       "         'peered': 1,\n",
       "         'beautifully': 1,\n",
       "         'make': 20,\n",
       "         'retorted': 1,\n",
       "         'imitated': 1,\n",
       "         'action': 1,\n",
       "         'want': 7,\n",
       "         'understand': 13,\n",
       "         'pressed': 5,\n",
       "         'sends': 1,\n",
       "         'gliding': 1,\n",
       "         'reverses': 1,\n",
       "         'motion': 8,\n",
       "         'saddle': 7,\n",
       "         'represents': 1,\n",
       "         'seat': 4,\n",
       "         'presently': 28,\n",
       "         'press': 1,\n",
       "         'vanish': 3,\n",
       "         'pass': 5,\n",
       "         'disappear': 2,\n",
       "         'good': 14,\n",
       "         'look': 20,\n",
       "         'too': 45,\n",
       "         'satisfy': 2,\n",
       "         'yourselves': 1,\n",
       "         'trickery': 2,\n",
       "         'waste': 5,\n",
       "         'told': 14,\n",
       "         'm': 10,\n",
       "         'quack': 1,\n",
       "         'minute': 22,\n",
       "         'changed': 5,\n",
       "         'forth': 6,\n",
       "         'towards': 47,\n",
       "         'suddenly': 22,\n",
       "         'lend': 1,\n",
       "         'turning': 4,\n",
       "         'individual': 1,\n",
       "         'own': 34,\n",
       "         'sent': 1,\n",
       "         'interminable': 2,\n",
       "         'voyage': 2,\n",
       "         'saw': 88,\n",
       "         'certain': 18,\n",
       "         'breath': 5,\n",
       "         'wind': 6,\n",
       "         'flame': 5,\n",
       "         'jumped': 2,\n",
       "         'blown': 4,\n",
       "         'swung': 2,\n",
       "         'indistinct': 4,\n",
       "         'ghost': 5,\n",
       "         'second': 11,\n",
       "         'eddy': 1,\n",
       "         'vanished': 12,\n",
       "         'bare': 6,\n",
       "         'everyone': 1,\n",
       "         'silent': 13,\n",
       "         'damned': 4,\n",
       "         'recovered': 3,\n",
       "         'stupor': 1,\n",
       "         'laughed': 9,\n",
       "         'cheerfully': 3,\n",
       "         'reminiscence': 2,\n",
       "         'went': 49,\n",
       "         'tobacco': 2,\n",
       "         'jar': 2,\n",
       "         'fill': 1,\n",
       "         'pipe': 5,\n",
       "         'stared': 9,\n",
       "         'earnest': 1,\n",
       "         'seriously': 3,\n",
       "         'believe': 10,\n",
       "         'travelled': 10,\n",
       "         'stooping': 2,\n",
       "         'spill': 1,\n",
       "         'turned': 21,\n",
       "         'lighting': 2,\n",
       "         'unhinged': 1,\n",
       "         'helped': 2,\n",
       "         'uncut': 1,\n",
       "         'big': 17,\n",
       "         'nearly': 7,\n",
       "         'indicated': 2,\n",
       "         'journey': 4,\n",
       "         'past': 16,\n",
       "         'interval': 5,\n",
       "         'inspiration': 1,\n",
       "         'anywhere': 1,\n",
       "         'presume': 1,\n",
       "         'moved': 9,\n",
       "         'since': 12,\n",
       "         'visible': 4,\n",
       "         'first': 49,\n",
       "         'thursday': 5,\n",
       "         'serious': 4,\n",
       "         'objections': 2,\n",
       "         'remarked': 4,\n",
       "         'air': 23,\n",
       "         'impartiality': 1,\n",
       "         'bit': 3,\n",
       "         'presentation': 2,\n",
       "         'below': 9,\n",
       "         'threshold': 1,\n",
       "         'diluted': 1,\n",
       "         'reassured': 2,\n",
       "         'simple': 5,\n",
       "         'point': 9,\n",
       "         'psychology': 1,\n",
       "         'plain': 7,\n",
       "         'helps': 1,\n",
       "         'delightfully': 1,\n",
       "         'appreciate': 3,\n",
       "         'spoke': 7,\n",
       "         'wheel': 1,\n",
       "         'spinning': 2,\n",
       "         'bullet': 1,\n",
       "         'flying': 1,\n",
       "         'travelling': 12,\n",
       "         'times': 13,\n",
       "         'hundred': 13,\n",
       "         'faster': 8,\n",
       "         'gets': 1,\n",
       "         'while': 20,\n",
       "         'impression': 6,\n",
       "         'creates': 1,\n",
       "         'fiftieth': 1,\n",
       "         'hundredth': 1,\n",
       "         'laughing': 7,\n",
       "         'vacant': 1,\n",
       "         'asked': 4,\n",
       "         'sounds': 7,\n",
       "         'plausible': 4,\n",
       "         'morrow': 4,\n",
       "         'common': 5,\n",
       "         'sense': 11,\n",
       "         'like': 74,\n",
       "         'itself': 8,\n",
       "         'therewith': 3,\n",
       "         'taking': 3,\n",
       "         'led': 5,\n",
       "         'draughty': 1,\n",
       "         'corridor': 5,\n",
       "         'remember': 12,\n",
       "         'flickering': 6,\n",
       "         'queer': 11,\n",
       "         'broad': 4,\n",
       "         'head': 23,\n",
       "         'silhouette': 1,\n",
       "         'dance': 6,\n",
       "         'shadows': 7,\n",
       "         'followed': 16,\n",
       "         'puzzled': 7,\n",
       "         'incredulous': 3,\n",
       "         'beheld': 2,\n",
       "         'edition': 1,\n",
       "         'parts': 4,\n",
       "         'nickel': 2,\n",
       "         'filed': 2,\n",
       "         'sawn': 1,\n",
       "         'rock': 3,\n",
       "         'crystal': 1,\n",
       "         'complete': 5,\n",
       "         'twisted': 1,\n",
       "         'bars': 10,\n",
       "         'lay': 16,\n",
       "         'unfinished': 1,\n",
       "         'bench': 4,\n",
       "         'beside': 8,\n",
       "         'sheets': 4,\n",
       "         'drawings': 2,\n",
       "         'quartz': 3,\n",
       "         'perfectly': 5,\n",
       "         'showed': 6,\n",
       "         'christmas': 1,\n",
       "         'holding': 5,\n",
       "         'aloft': 1,\n",
       "         'intend': 1,\n",
       "         'explore': 2,\n",
       "         'life': 16,\n",
       "         'none': 9,\n",
       "         'knew': 15,\n",
       "         'take': 8,\n",
       "         'eye': 8,\n",
       "         'winked': 1,\n",
       "         'solemnly': 3,\n",
       "         'ii': 1,\n",
       "         'believed': 2,\n",
       "         'those': 18,\n",
       "         'clever': 2,\n",
       "         'felt': 57,\n",
       "         'suspected': 3,\n",
       "         'subtle': 3,\n",
       "         'reserve': 1,\n",
       "         'ingenuity': 1,\n",
       "         'ambush': 1,\n",
       "         'lucid': 1,\n",
       "         'frankness': 1,\n",
       "         'shown': 2,\n",
       "         'explained': 2,\n",
       "         'less': 16,\n",
       "         'scepticism': 1,\n",
       "         'perceived': 5,\n",
       "         'motives': 1,\n",
       "         'pork': 1,\n",
       "         'butcher': 1,\n",
       "         'touch': 4,\n",
       "         'whim': 1,\n",
       "         'among': 33,\n",
       "         'elements': 1,\n",
       "         'distrusted': 1,\n",
       "         'frame': 4,\n",
       "         'tricks': 1,\n",
       "         'mistake': 2,\n",
       "         'easily': 3,\n",
       "         'deportment': 1,\n",
       "         'somehow': 7,\n",
       "         'aware': 1,\n",
       "         'trusting': 1,\n",
       "         'their': 91,\n",
       "         'reputations': 1,\n",
       "         'judgment': 2,\n",
       "         'furnishing': 1,\n",
       "         'nursery': 1,\n",
       "         'egg': 1,\n",
       "         'shell': 1,\n",
       "         'china': 2,\n",
       "         'next': 14,\n",
       "         'potentialities': 1,\n",
       "         'ran': 17,\n",
       "         'doubt': 13,\n",
       "         'minds': 1,\n",
       "         'plausibility': 1,\n",
       "         'practical': 1,\n",
       "         'incredibleness': 1,\n",
       "         'possibilities': 2,\n",
       "         'anachronism': 1,\n",
       "         'utter': 2,\n",
       "         'confusion': 6,\n",
       "         'preoccupied': 1,\n",
       "         'discussing': 1,\n",
       "         'whom': 3,\n",
       "         'met': 9,\n",
       "         'friday': 3,\n",
       "         'linnaean': 1,\n",
       "         'similar': 2,\n",
       "         'tubingen': 1,\n",
       "         'laid': 2,\n",
       "         'considerable': 3,\n",
       "         'stress': 1,\n",
       "         'blowing': 1,\n",
       "         'candle': 2,\n",
       "         'richmond': 1,\n",
       "         'suppose': 13,\n",
       "         'constant': 2,\n",
       "         'guests': 3,\n",
       "         'arriving': 1,\n",
       "         'late': 6,\n",
       "         'found': 44,\n",
       "         'five': 4,\n",
       "         'already': 19,\n",
       "         'assembled': 1,\n",
       "         'drawing': 1,\n",
       "         'standing': 9,\n",
       "         'sheet': 1,\n",
       "         'paper': 6,\n",
       "         'watch': 10,\n",
       "         'half': 20,\n",
       "         'seven': 6,\n",
       "         'd': 3,\n",
       "         'naming': 2,\n",
       "         'host': 2,\n",
       "         've': 4,\n",
       "         'come': 30,\n",
       "         'unavoidably': 1,\n",
       "         'detained': 1,\n",
       "         'asks': 1,\n",
       "         'note': 2,\n",
       "         'lead': 2,\n",
       "         'says': 1,\n",
       "         'll': 5,\n",
       "         'comes': 7,\n",
       "         'seems': 2,\n",
       "         'pity': 2,\n",
       "         'spoil': 1,\n",
       "         'editor': 20,\n",
       "         'known': 3,\n",
       "         'daily': 3,\n",
       "         'thereupon': 1,\n",
       "         'doctor': 3,\n",
       "         'rang': 3,\n",
       "         'bell': 3,\n",
       "         'besides': 4,\n",
       "         'myself': 51,\n",
       "         'attended': 1,\n",
       "         'previous': 4,\n",
       "         'blank': 3,\n",
       "         'aforementioned': 1,\n",
       "         'journalist': 9,\n",
       "         'quiet': 6,\n",
       "         'shy': 2,\n",
       "         'beard': 1,\n",
       "         'didn': 1,\n",
       "         'observation': 1,\n",
       "         'opened': 9,\n",
       "         'mouth': 7,\n",
       "         'evening': 11,\n",
       "         'speculation': 2,\n",
       "         'absence': 4,\n",
       "         'jocular': 1,\n",
       "         'spirit': 5,\n",
       "         'wanted': 8,\n",
       "         'volunteered': 1,\n",
       "         'wooden': 1,\n",
       "         'ingenious': 2,\n",
       "         'witnessed': 1,\n",
       "         'day': 36,\n",
       "         'week': 4,\n",
       "         'midst': 1,\n",
       "         'exposition': 1,\n",
       "         'door': 17,\n",
       "         'noise': 3,\n",
       "         'facing': 4,\n",
       "         'hallo': 1,\n",
       "         'wider': 2,\n",
       "         'gave': 12,\n",
       "         'cry': 2,\n",
       "         'surprise': 5,\n",
       "         'heavens': 2,\n",
       "         'tableful': 1,\n",
       "         'amazing': 2,\n",
       "         ...})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [['the', 'time', 'machine', 'by', 'h', 'g', 'wells', ''],\n",
    "#  [''],\n",
    "#  [''],\n",
    "# tokens\n",
    "word_list = []\n",
    "for row in tokens:  # tokens: 3221行, 每行为单词的列表\n",
    "#     print(row)  # row: 1行, 单词的列表, ['the', 'time', 'machine', 'by', 'h', 'g', 'wells', '']\n",
    "#     print(len(row))  # 8，每行的单词数\n",
    "    for word in row:  \n",
    "        word_list.append(word)\n",
    "#         print(word)  # word: the, 每一个单词\n",
    "collections.Counter(word_list)\n",
    "\n",
    "# counter = count_corpus(tokens) \n",
    "# counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_k17qg7x",
    "id": "DB6949BC67FF4C7481DFFD00FE64BE56",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "我们看一个例子，这里我们尝试用Time Machine作为语料构建字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T14:08:12.916151Z",
     "start_time": "2020-02-13T14:08:12.786249Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "23"
    },
    "graffitiCellId": "id_hm9y6bm",
    "id": "1BE94FF518DB4C4A8CDFB95C0262B47E",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 0), ('the', 1), ('time', 2), ('machine', 3), ('by', 4), ('h', 5), ('g', 6), ('wells', 7), ('i', 8), ('traveller', 9)]\n",
      "['', 'the', 'time', 'machine', 'by', 'h', 'g', 'wells', 'i', 'traveller']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = Vocab(tokens)\n",
    "print(list(vocab.token_to_idx.items())[0:10])  # 已知词tokens，取出索引idx\n",
    "print(list(vocab.idx_to_token[0:10]))  # 已知索引idx，取出词tokens\n",
    "vocab.to_tokens(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_l6pjfl7",
    "id": "73D0F629056F41B59D4A53F15BFAB552",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 将词转为索引\n",
    "\n",
    "使用字典，我们可以将原文本中的句子从单词序列转换为索引序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T14:08:13.055590Z",
     "start_time": "2020-02-13T14:08:13.017512Z"
    },
    "graffitiCellId": "id_k48bsl2",
    "id": "9FBB71C21B5C4F5283C70CFE3BB07112",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words: ['the', 'time', 'traveller', 'for', 'so', 'it', 'will', 'be', 'convenient', 'to', 'speak', 'of', 'him', '']\n",
      "indices: [1, 2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0]\n",
      "words: ['was', 'expounding', 'a', 'recondite', 'matter', 'to', 'us', 'his', 'grey', 'eyes', 'shone', 'and']\n",
      "indices: [20, 21, 22, 23, 24, 16, 25, 26, 27, 28, 29, 30]\n"
     ]
    }
   ],
   "source": [
    "for i in range(8, 10):\n",
    "    print('words:', tokens[i])\n",
    "    print('indices:', vocab[tokens[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_q6fupul",
    "id": "EA20BC8762A74B188D3FDD761BFEDE98",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 用现有工具进行分词\n",
    "\n",
    "我们前面介绍的分词方式非常简单，它至少有以下几个缺点:\n",
    "\n",
    "1. 标点符号通常可以提供语义信息，但是我们的方法直接将其丢弃了\n",
    "2. 类似“shouldn't\", \"doesn't\"这样的词会被错误地处理\n",
    "3. 类似\"Mr.\", \"Dr.\"这样的词会被错误地处理\n",
    "\n",
    "我们可以通过引入更复杂的规则来解决这些问题，但是事实上，有一些现有的工具可以很好地进行分词，我们在这里简单介绍其中的两个：[spaCy](https://spacy.io/)和[NLTK](https://www.nltk.org/)。\n",
    "\n",
    "下面是一个简单的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T14:08:13.155967Z",
     "start_time": "2020-02-13T14:08:13.059940Z"
    },
    "graffitiCellId": "id_7u3knll",
    "id": "46F5F57611E248ECB51F04BD0104E278",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"Mr. Chen doesn't agree with my suggestion.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_ae3i5g2",
    "id": "7D5831E3D5AD4FF48155334F73065451",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "spaCy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T14:08:14.184749Z",
     "start_time": "2020-02-13T14:08:13.161124Z"
    },
    "graffitiCellId": "id_uz6civu",
    "id": "30D69C6B1BE44362BA556E2E5EEF493A",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr.', 'Chen', 'does', \"n't\", 'agree', 'with', 'my', 'suggestion', '.']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(text)\n",
    "print([token.text for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "765CC9B5A1C348A58A2B340ADC532FD1",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T14:08:14.632190Z",
     "start_time": "2020-02-13T14:08:14.186892Z"
    },
    "graffitiCellId": "id_r13iwga",
    "id": "B83D30D3670B44A38527B4943BE4DBE0",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr.', 'Chen', 'does', \"n't\", 'agree', 'with', 'my', 'suggestion', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import data\n",
    "# data.path.append('/home/kesci/input/nltk_data3784/nltk_data')\n",
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "269.661px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
